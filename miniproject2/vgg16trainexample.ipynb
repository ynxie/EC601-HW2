{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a short configuration name [default = \"default\"]: vgg_16\n",
      "#####2583#####\n",
      "Tensor(\"batch_join:0\", shape=(64, 56, 56, 3), dtype=uint8, device=/device:CPU:0)\n",
      "Iteration: 250, Loss: 2.611, Accuracy: 0.4015\n",
      "Iteration: 500, Loss: 2.355, Accuracy: 0.4814\n",
      "Iteration: 750, Loss: 2.264, Accuracy: 0.5191\n",
      "Iteration: 1000, Loss: 2.217, Accuracy: 0.5299\n",
      "Iteration: 1250, Loss: 2.167, Accuracy: 0.5472\n",
      "Iteration: 1500, Loss: 2.119, Accuracy: 0.5566\n",
      "Iteration: 1750, Loss: 2.083, Accuracy: 0.5619\n",
      "#####861#####\n",
      "Tensor(\"batch_join:0\", shape=(64, 56, 56, 3), dtype=uint8, device=/device:CPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/cnn/vgg_16/model-2000\n",
      "Validation. Loss: 2.296, Accuracy: 0.4195\n",
      "Iteration: 2000, Loss: 2.062, Accuracy: 0.5619\n"
     ]
    }
   ],
   "source": [
    "from vgg_16 import *\n",
    "# from logistic_regression import *\n",
    "# from single_layer_nn import *\n",
    "from metrics import *\n",
    "from losses import *\n",
    "from input_pipe import *\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from cnn import *\n",
    "\n",
    "\n",
    "\n",
    "class TrainConfig(object):\n",
    "  \"\"\"Training configuration\"\"\"\n",
    "  batch_size = 64\n",
    "  num_epochs = 50\n",
    "  summary_interval = 250\n",
    "  eval_interval = 2000  # must be integer multiple of summary_interval\n",
    "  lr = 0.01  # learning rate\n",
    "  reg = 5e-4  # regularization\n",
    "  momentum = 0.9\n",
    "  dropout_keep_prob = 0.5\n",
    "  model_name = 'cnn'  # choose model\n",
    "  model = staticmethod(globals()[model_name])  # gets model by name\n",
    "  path='flowers'\n",
    "  class_num=5\n",
    "\n",
    "class TrainControl(object):\n",
    "  \"\"\"Basic training control\n",
    "\n",
    "  Decreases learning rate (lr), terminates training after 3 lr decreases\n",
    "\n",
    "  Track validation accuracy, decrease lr by 1/5th when:\n",
    "    1. validation accuracy worsens\n",
    "    2. less than 0.2% absolute improvement last 3 iterations\n",
    "  \"\"\"\n",
    "  def __init__(self, lr):\n",
    "    self.val_accs = []\n",
    "    self.lr = lr\n",
    "    self.num_lr_updates = 0\n",
    "    self.lr_factor = 1/5\n",
    "\n",
    "  def add_val_acc(self, loss):\n",
    "    self.val_accs.append(loss)\n",
    "\n",
    "  def update_lr(self, sess):\n",
    "    if len(self.val_accs) < 3:\n",
    "      return\n",
    "    decrease = False\n",
    "    # decrease LR if validation acc worsens\n",
    "    if self.val_accs[-1] < max(self.val_accs):\n",
    "      decrease = True\n",
    "    avg_2 = (self.val_accs[-2] + self.val_accs[-3]) / 2\n",
    "    # decrease LR if validation accuracy doesn't improve by 0.2% (absolute)\n",
    "    if abs(self.val_accs[-1] - avg_2) < 0.002:\n",
    "      decrease = True\n",
    "    if decrease:\n",
    "      old_lr = sess.run(self.lr)\n",
    "      self.lr.load(old_lr * self.lr_factor)\n",
    "      self.num_lr_updates += 1\n",
    "      print('*** New learning rate: {}'.format(old_lr * self.lr_factor))\n",
    "\n",
    "  def done(self):\n",
    "    if self.num_lr_updates > 3:  # terminate training after 3 lr decreases\n",
    "      return True\n",
    "    else:\n",
    "      return False\n",
    "\n",
    "\n",
    "def optimizer(loss, config):\n",
    "  \"\"\"Add training operation, global_step and learning rate variable to Graph\n",
    "\n",
    "  Args:\n",
    "    loss: model loss tensor\n",
    "    config: training configuration object\n",
    "\n",
    "  Returns:\n",
    "    (train_op, global_step, lr)\n",
    "  \"\"\"\n",
    "  lr = tf.Variable(config.lr, trainable=False, dtype=tf.float32)\n",
    "  global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "  optim = tf.train.MomentumOptimizer(lr, config.momentum,\n",
    "                                     use_nesterov=True)\n",
    "  train_op = optim.minimize(loss, global_step=global_step)\n",
    "\n",
    "  return train_op, global_step, lr\n",
    "\n",
    "\n",
    "def get_logdir():\n",
    "  \"\"\"Return unique logdir based on datetime\"\"\"\n",
    "  now = datetime.utcnow().strftime(\"%m%d%H%M%S\")\n",
    "  logdir = \"run-{}/\".format(now)\n",
    "\n",
    "  return logdir\n",
    "\n",
    "\n",
    "def model(mode, config):\n",
    "  \"\"\"Pull it all together: input queue, inference model and loss functions\n",
    "\n",
    "  Args:\n",
    "    mode: 'train' or 'val'\n",
    "    config: model configuration object\n",
    "\n",
    "  Returns:\n",
    "    loss and accuracy tensors\n",
    "  \"\"\"\n",
    "  # preprocess images on cpu - send to gpu as uint8 for speed\n",
    "  with tf.device('/cpu:0'):\n",
    "    imgs, labels = batch_q(mode, config)\n",
    "    print (imgs)\n",
    "\n",
    "  logits = config.model(imgs, config)\n",
    "  softmax_ce_loss(logits, labels)\n",
    "  acc = accuracy(logits, labels)\n",
    "  total_loss = tf.add_n(tf.get_collection(tf.GraphKeys.LOSSES), name='total_loss')\n",
    "  total_loss += tf.add_n(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES),\n",
    "                         name='total_loss') * config.reg\n",
    "  for l2 in tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES):\n",
    "    # add l2 loss histograms to TensorBoard and cleanup var names\n",
    "    name = 'l2_loss_' + l2.name.split('/')[0]\n",
    "    tf.summary.histogram(name, l2)\n",
    "\n",
    "  return total_loss, acc\n",
    "\n",
    "\n",
    "def evaluate(ckpt):\n",
    "  \"\"\"Load checkpoint and run on validation set\"\"\"\n",
    "  config = TrainConfig()\n",
    "  config.dropout_keep_prob = 1.0  # disable dropout for validation\n",
    "  config.num_epochs = 1\n",
    "  accs, losses = [], []\n",
    "\n",
    "  with tf.Graph().as_default():\n",
    "    loss, acc = model('val', config)\n",
    "    saver = tf.train.Saver()\n",
    "    init = tf.group(tf.global_variables_initializer(),\n",
    "                    tf.local_variables_initializer())\n",
    "    with tf.Session() as sess:\n",
    "      init.run()\n",
    "      saver.restore(sess, ckpt)\n",
    "      coord = tf.train.Coordinator()\n",
    "      threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "      try:\n",
    "        while not coord.should_stop():\n",
    "          step_loss, step_acc = sess.run([loss, acc])\n",
    "          accs.append(step_acc)\n",
    "          losses.append(step_loss)\n",
    "      except tf.errors.OutOfRangeError as e:\n",
    "        coord.request_stop(e)\n",
    "      finally:\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "  mean_loss, mean_acc = np.mean(losses), np.mean(accs)\n",
    "  print('Validation. Loss: {:.3f}, Accuracy: {:.4f}'.\n",
    "        format(mean_loss, mean_acc))\n",
    "\n",
    "  return mean_loss, mean_acc\n",
    "\n",
    "\n",
    "def options(config):\n",
    "  \"\"\"Get user input on training options\"\"\"\n",
    "  q = input('Enter a short configuration name [default = \"default\"]: ')\n",
    "  if len(q) == 0:\n",
    "    q = 'default'\n",
    "  config.config_name = q\n",
    "  # tensorboard and checkpoint log directory names\n",
    "  ckpt_path = 'checkpoints/' + config.model_name + '/' + config.config_name\n",
    "  tflog_path = ('tf_logs/' + config.model_name + '/' +\n",
    "                config.config_name + '/' + get_logdir())\n",
    "  checkpoint = None\n",
    "  # TODO: spaghetti mess, clean up:\n",
    "  if not os.path.isdir(ckpt_path):\n",
    "    os.makedirs(ckpt_path)\n",
    "    filenames = glob.glob('*.py')\n",
    "    for filename in filenames:\n",
    "      shutil.copy(filename, ckpt_path)\n",
    "    return False, ckpt_path, tflog_path, checkpoint\n",
    "  else:\n",
    "    filenames = glob.glob('*.py')\n",
    "    for filename in filenames:\n",
    "      shutil.copy(filename, ckpt_path)\n",
    "    while True:\n",
    "      q1 = input('Continue previous training? [Y/n]: ')\n",
    "      if len(q1) == 0 or q1 == 'n' or q1 == 'Y':\n",
    "        break\n",
    "    if q1 == 'n':\n",
    "      return False, ckpt_path, tflog_path, checkpoint\n",
    "    else:\n",
    "      q2 = input('Enter checkpoint name [defaults to most recent]: ')\n",
    "      if len(q2) == 0:\n",
    "        checkpoint = tf.train.latest_checkpoint(ckpt_path)\n",
    "      else:\n",
    "        checkpoint = ckpt_path + '/' + q2\n",
    "      return True, ckpt_path, tflog_path, checkpoint\n",
    "\n",
    "\n",
    "def train():\n",
    "  \"\"\"Build Graph, launch session and train.\"\"\"\n",
    "\n",
    "  config = TrainConfig()\n",
    "  continue_train, ckpt_path, tflog_path, checkpoint = options(config)\n",
    "  g = tf.Graph()\n",
    "  with g.as_default():\n",
    "    loss, acc = model('train', config)\n",
    "    train_op, g_step, lr = optimizer(loss, config)\n",
    "    controller = TrainControl(lr)\n",
    "    # put variables in graph to hold validation acc and loss for TensorBoard viewing\n",
    "    val_acc = tf.Variable(0.0, trainable=False)\n",
    "    val_loss = tf.Variable(0.0, trainable=False)\n",
    "    tf.summary.scalar('val_loss', val_loss)\n",
    "    tf.summary.scalar('val_accuracy', val_acc)\n",
    "    init = tf.group(tf.global_variables_initializer(),\n",
    "                    tf.local_variables_initializer())\n",
    "    # histograms of all variables to TensorBoard\n",
    "    [tf.summary.histogram(v.name.replace(':', '_'), v)\n",
    "     for v in tf.trainable_variables()]\n",
    "    # next line only needed for batch normalization (updates beta and gamma)\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    summ = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver(max_to_keep=1)\n",
    "    writer = tf.summary.FileWriter(tflog_path, g)\n",
    "    with tf.Session() as sess:\n",
    "      init.run()\n",
    "      if continue_train:\n",
    "        saver.restore(sess, checkpoint)\n",
    "      coord = tf.train.Coordinator()\n",
    "      threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "      try:\n",
    "        losses, accs = [], []  # hold running averages for test loss/acc\n",
    "        while not coord.should_stop():\n",
    "          step_loss, _, step, step_acc, __ = sess.run([loss, train_op,\n",
    "                                                       g_step, acc, extra_update_ops])\n",
    "          losses.append(step_loss)\n",
    "          accs.append(step_acc)\n",
    "          if step % config.eval_interval == 0:\n",
    "            ckpt = saver.save(sess, ckpt_path + '/model', step)\n",
    "            mean_loss, mean_acc = evaluate(ckpt)\n",
    "            val_acc.load(mean_acc)\n",
    "            val_loss.load(mean_loss)\n",
    "            controller.add_val_acc(mean_acc)\n",
    "            controller.update_lr(sess)\n",
    "            if controller.done():\n",
    "              break\n",
    "          if step % config.summary_interval == 0:\n",
    "            writer.add_summary(sess.run(summ), step)\n",
    "            print('Iteration: {}, Loss: {:.3f}, Accuracy: {:.4f}'.\n",
    "                  format(step, np.mean(losses), np.mean(accs)))\n",
    "            losses, accs = [], []\n",
    "      except tf.errors.OutOfRangeError as e:\n",
    "        coord.request_stop(e)\n",
    "      finally:\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  '''\n",
    "  config = TrainConfig()\n",
    "  continue_train, ckpt_path, tflog_path, checkpoint = options(config)\n",
    "  total_loss, acc=model('train',config)\n",
    "  print(total_loss)\n",
    "  '''\n",
    "  train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
